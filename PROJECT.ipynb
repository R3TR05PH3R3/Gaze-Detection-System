{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Detection Term Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first started our term project by experimenting on RGB photos<br>\n",
    "to see if we can detect their eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked with some errors. Now it is time to detect Irises from a live camera (God I hope so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # opens the cameraer\n",
    "counter = 0\n",
    "while True:\n",
    "    ret, frame = cap.read() # reads frames from the camera\n",
    "\n",
    "    # Calculate the dimensions of each quarter\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    quarter_height = frame_height // 2\n",
    "    quarter_width = frame_width // 2\n",
    "\n",
    "    # Split the frame into four equal parts\n",
    "    top_left = frame[0:quarter_height, 0:quarter_width]\n",
    "    top_right = frame[0:quarter_height, quarter_width:frame_width]\n",
    "    bottom_left = frame[quarter_height:frame_height, 0:quarter_width]\n",
    "    bottom_right = frame[quarter_height:frame_height, quarter_width:frame_width]\n",
    "\n",
    "    if not ret: # if no frame is captured ( if cam closes or deactivates smhow) finish the loop \n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Histogram Equalization\n",
    "    gray_eq = cv2.equalizeHist(gray)  \n",
    "    \n",
    "    # eyes_cascade has the contents of an .xml file, ,\n",
    "    # which is a code specially designed for eye and iris detection\n",
    "    # named haarcascade_eye.xml. (yes, we fetched it from a GitHub page which will has its link in our appendices)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=2)\n",
    "    \n",
    "    # This way, we can detect the eye regions (yes, not iris) at the given frame (from camera, remember)\n",
    "    for (x, y, w, h) in eyes:\n",
    "        counter = counter + 1\n",
    "        # after detecting the eye regions, we simply draw rectangles around these eye regions\n",
    "        new_w = int(w * 0.5)\n",
    "        new_h = int(h * 0.5)\n",
    "        x += int((w - new_w) / 2)\n",
    "        y += int((h - new_h) / 2)\n",
    "        w = new_w\n",
    "        h = new_h\n",
    "        \n",
    "        #Eye region crop\n",
    "        eye_frame = frame[y:y + h, x:x + w]\n",
    "        \n",
    "        # then we extract the eye regions from the grayscale frame\n",
    "        eye_gray = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # applies adaptive tresholding to separate irises from the rest of the eye\n",
    "        # this creates an iris region as a result\n",
    "        adaptive_th = cv2.adaptiveThreshold(eye_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 3)\n",
    "\n",
    "        # applies morphology operations to remove noise and fill gaps\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "        iris = cv2.morphologyEx(adaptive_th, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        \n",
    "        #finds contours in the iris region (iris region is created above)\n",
    "        contours, _ = cv2.findContours(iris, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        valid_contours = []\n",
    "        for contour in contours:\n",
    "            # Filters out contours based on aspect ratio and area\n",
    "            x_contour, y_contour, w_contour, h_contour = cv2.boundingRect(contour)\n",
    "            aspect_ratio = float(w_contour) / h_contour\n",
    "            contour_area = cv2.contourArea(contour)\n",
    "            \n",
    "            # Adjusts these thresholds according to your specific requirements\n",
    "            if aspect_ratio > 0.2 and aspect_ratio < 1.8 and contour_area > 100:\n",
    "                valid_contours.append(contour)\n",
    "\n",
    "        if len(contours) > 0:\n",
    "            # finds the largest contour in the iris region\n",
    "            iris_contour = max(contours, key=cv2.contourArea)\n",
    "            \n",
    "            #then we findd the center of the iris contour\n",
    "            moments = cv2.moments(iris_contour)\n",
    "            if moments['m00'] != 0:\n",
    "                cx = int(moments['m10'] / moments['m00'])\n",
    "                cy = int(moments['m01'] / moments['m00'])\n",
    "                inner_radius = int(w/8)\n",
    "                # draws iris  and pupil frames\n",
    "                cv2.circle(frame, (x+cx, y+cy), inner_radius, (0, 0, 255), 2)\n",
    "                # Estimate gaze direction based on previous and current coordinates\n",
    "            \n",
    "                 # Determine the position of the eye\n",
    "                eye_position = \"None\\nNone\"\n",
    "                if x > quarter_width and y > quarter_height:\n",
    "                    eye_position = \"Down\\nRight\"\n",
    "                elif x <= quarter_width and y > quarter_height:\n",
    "                    eye_position = \"Down\\nLeft\"\n",
    "                elif x > quarter_width and y <= quarter_height:\n",
    "                    eye_position = \"Up\\nRight\"\n",
    "                elif x < quarter_width and y < quarter_height:\n",
    "                    eye_position = \"Up\\nLeft\"\n",
    "                position_lines = eye_position.split(\"\\n\")\n",
    "\n",
    "                cv2.putText(frame, position_lines[0], (x - 20, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, position_lines[1], (x - 20, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        frame[y:y + h, x:x + w] = eye_frame\n",
    "    if counter == 0:\n",
    "        cv2.putText(frame, \"No eyes detected!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    else:\n",
    "        stringer = \"Detected Eye #: \" + str(counter)\n",
    "        cv2.putText(frame, stringer, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    counter = 0\n",
    "    # displays result\n",
    "    cv2.imshow('Eye Detection and Iris Tracking', frame)\n",
    "    \n",
    "    # if the 'q' or 'Q' keys are pressed, breaks the loop\n",
    "    # which closes the program\n",
    "    # wait for user input to close the program\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27:  # 27 is the ASCII code for the 'Esc' key\n",
    "        break\n",
    "        \n",
    "    elif key == ord('q') or key == ord('Q'):\n",
    "        break\n",
    " \n",
    "cap.release()  \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
